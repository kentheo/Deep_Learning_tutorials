{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CO460 - Deep Learning - Tutorial 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, there are two parts:\n",
    "\n",
    "First we demonstrate:\n",
    "- A Generative Adversarial Network (GAN) \n",
    "- A Conditional Generative Adversarial Network (cGAN)\n",
    "\n",
    "Second:\n",
    "- Exercise and experimentations with GAN architectures and sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import torch.nn.functional as F\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "GPU = True\n",
    "device_idx = 0\n",
    "if GPU:\n",
    "    device = torch.device(\"cuda:\" + str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5b8dc8cef0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We set a random seed to ensure that your results are reproducible.\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Normalization: \n",
    "\n",
    "$ x_{norm} = \\frac{x-\\mu}{\\sigma} $\n",
    "\n",
    "* Same as in the previous tutorial: input after normalization $\\in [-1,1] $\n",
    "* Activation function of the Generator output layer should be tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dat = datasets.MNIST(\n",
    "    \"data/\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dat = datasets.MNIST(\"./data/\", train=False, transform=transform)\n",
    "\n",
    "denorm = denorm_for_tanh\n",
    "\n",
    "if not os.path.exists('./cGAN'):\n",
    "    os.mkdir('./cGAN')\n",
    "    \n",
    "if not os.path.exists('./GAN'):\n",
    "    os.mkdir('./GAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 2e-4\n",
    "noise_dim = 128\n",
    "h_dim1 = 256\n",
    "h_dim2 = 512\n",
    "h_dim3 = 1024\n",
    "in_dim = np.prod(train_dat[0][0].shape)\n",
    "out_shape = train_dat[0][0].shape\n",
    "\n",
    "sample_interval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dat, batch_size, shuffle=True, num_workers=16)\n",
    "test_loader = DataLoader(test_dat, batch_size, shuffle=False, num_workers=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I - Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder:\n",
    "\n",
    "**Zero-Sum game objective**:\n",
    "\n",
    "$$\\min_{\\theta_G}\\max_{\\theta_D} \\mathbb{E}_{x\\sim p_{data}}[\\log D(x)] + \\mathbb{E}_{z\\sim p_z}[\\log (1- D(G(z)))] \n",
    "\\\\= \\min_{\\theta_G}\\max_{\\theta_D} \\sum_{x,z} y_x \\log D(x) +(1-y_{G(z)})\\log (1-D(G(z))) : Binary Cross Entropy\n",
    "$$\n",
    "\n",
    "where $y_x = 1, y_{G(z)} = 0 $\n",
    "\n",
    "\n",
    "**Baseline Algorithm**:\n",
    "\n",
    "- For N epochs repeat:\n",
    "    1. Sample N samples $x\\sim p_{data}$ and N samples $z\\sim p_{z}$\n",
    "    2. Predict the labels that the Discriminator assigns.  Then backpropagate the error across the Discriminator $\\to$ gradient ascent for the Discriminator.\n",
    "    3. Predict the new labels that the Discriminator assigns to fake examples. Then backpropagate the error across the Generator $\\to$ gradient descent for the Generator.\n",
    "   \n",
    "**Alternatively**:\n",
    "\n",
    "- Sample some real data and some fake ones.\n",
    "- Train the Discriminator for a few steps.\n",
    "- Sample some fake data\n",
    "- Then train the Generator for one step.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "- Usually for the Generator, instead of the original function we minimize: $\\min_{\\theta_G} - \\mathbb{E}_{z\\sim p_z}[\\log D(G(z))] $\n",
    "\n",
    "https://arxiv.org/pdf/1406.2661.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model - GAN structure\n",
    "\n",
    "<img src=\"imgs/GAN.png\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim = 128, h_dim1 = 256, \\\n",
    "                                            h_dim2 = 512, h_dim3 = 1024, out_shape = out_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.out_shape = out_shape\n",
    "        \n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(in_dim, h_dim1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(            \n",
    "            nn.Linear(h_dim1,h_dim2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(h_dim2, h_dim3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(h_dim3, np.prod(out_shape)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        x = x.view(x.size(0),*self.out_shape)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class Discriminator(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim = 784, h_dim1 = 1024, \\\n",
    "                                               h_dim2 = 512, h_dim3 = 256, out_dim = 1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.hidden0 = nn.Sequential( \n",
    "            nn.Linear(in_dim, h_dim1),\n",
    "            nn.ReLU()\n",
    "\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(h_dim1, h_dim2),\n",
    "            nn.ReLU()\n",
    "\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(h_dim2, h_dim3),\n",
    "            nn.ReLU()\n",
    "\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.Linear(h_dim3, out_dim),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(in_dim = noise_dim, h_dim1= h_dim1, \\\n",
    "                              h_dim2=h_dim2, h_dim3 = h_dim3, out_shape = out_shape)\n",
    "discriminator = Discriminator(in_dim = in_dim, h_dim1= h_dim3, \\\n",
    "                              h_dim2=h_dim2, h_dim3 = h_dim1, out_dim = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss(reduction='mean')\n",
    "def loss_function(out, label):\n",
    "    loss = criterion(out, label)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model and print number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/lab/course/416/venv/lib/python3.6/site-packages/torch/cuda/__init__.py:117: UserWarning: \n",
      "    Found GPU0 NVS 310 which is of cuda capability 2.1.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of generator parameters is: 1493520\n",
      "Generator(\n",
      "  (hidden0): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (hidden1): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (hidden2): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=784, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "Total number of discriminator parameters is: 1460225\n",
      "Discriminator(\n",
      "  (hidden0): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (hidden1): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (hidden2): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)\n",
    "\n",
    "params = sum(p.numel() for p in generator.parameters() if p.requires_grad)\n",
    "print(\"Total number of generator parameters is: {}\".format(params))  # what would the number actually be\n",
    "print(generator)\n",
    "\n",
    "params = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n",
    "print(\"Total number of discriminator parameters is: {}\".format(params))  # what would the number actually be\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose and initialize optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a noise distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(batch_size, noise_dim):\n",
    "    noise = torch.randn(batch_size, noise_dim)\n",
    "    return noise                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4d0e760bf498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# 1)Sample noise as generator input, 2) generate a batch of images, 3) assing a 0 as ground truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/lab/course/416/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a2dba78d4699>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/lab/course/416/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/lab/course/416/venv/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/lab/course/416/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/lab/course/416/venv/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/lab/course/416/venv/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device"
     ]
    }
   ],
   "source": [
    "g_losses = []\n",
    "d_losses = []\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "num_epochs = 100 \n",
    "\n",
    "fixed_noise = generate_noise(batch_size, noise_dim)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    g_loss_epoch = 0\n",
    "    d_loss_epoch = 0 \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        \n",
    "        img, _ = data\n",
    "        # 1) sample some real data, 2) assign a 1 as ground truth\n",
    "        img = img.to(device)\n",
    "        valid = torch.ones(img.size(0), 1, requires_grad=False).to(device)\n",
    "        \n",
    "        # 1)Sample noise as generator input, 2) generate a batch of images, 3) assing a 0 as ground truth\n",
    "        z = generate_noise(img.size(0), noise_dim).to(device)\n",
    "        gen_imgs = generator(z)\n",
    "        fake = torch.zeros(img.size(0), 1, requires_grad=False).to(device)\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = loss_function(discriminator(img), valid)\n",
    "        fake_loss = loss_function(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = real_loss + fake_loss\n",
    "\n",
    "        d_loss.backward()\n",
    "        d_loss_epoch += d_loss.item()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = loss_function(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        g_loss_epoch += g_loss.item()\n",
    "        optimizer_G.step()\n",
    "\n",
    "\n",
    "    print('epoch [{}/{}], generator loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, g_loss_epoch / len(train_loader)))\n",
    "    g_losses.append(g_loss_epoch/ len(train_loader))\n",
    "    print('epoch [{}/{}], discriminator loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, d_loss_epoch / len(train_loader)))\n",
    "    d_losses.append(d_loss_epoch/ len(train_loader))\n",
    "    if epoch % sample_interval == 0:\n",
    "        save_image(denorm(generator(fixed_noise.to(device))).cpu(), './GAN/samples_epoch_{}.png'.format(epoch),nrow = 8)\n",
    "    torch.save(generator.state_dict(), './GAN/generator.pth')\n",
    "    torch.save(discriminator.state_dict(), './GAN/discriminator.pth')\n",
    "    \n",
    "np.save('./GAN/generator_losses.npy', np.array(g_losses))\n",
    "np.save('./GAN/discriminator_losses.npy', np.array(d_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "generator_losses = np.load('./GAN/generator_losses.npy')\n",
    "plt.plot(list(range(0,generator_losses.shape[0])), generator_losses)\n",
    "plt.title('Generator Loss')\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "discriminator_losses = np.load('./GAN/discriminator_losses.npy')\n",
    "plt.plot(list(range(0,discriminator_losses.shape[0])), discriminator_losses)\n",
    "plt.title('Discriminator Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_state_dict(torch.load(\"./GAN/generator.pth\"))\n",
    "\n",
    "generator.eval()\n",
    "n_samples = 32\n",
    "with torch.no_grad():\n",
    "    z = generate_noise(n_samples*n_samples, noise_dim).to(device)\n",
    "    samples = generator(z)\n",
    "    save_image(denorm(samples).type(torch.FloatTensor).cpu(), './GAN/samples' + '.png',nrow = n_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of conditional GAN: \n",
    "\n",
    "* $\\mathbf{x}$ refers to a train datum\n",
    "* $\\mathbf{y}$ refers to the corresponding label\n",
    "* $\\mathbf{z}$ refers to random noise vector\n",
    "<img src=\"./imgs/cGAN.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "learning_rate = 0.0002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "\n",
    "latent_dim = 128\n",
    "num_classes = 10\n",
    "\n",
    "num_workers = 16\n",
    "sample_interval = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dat, batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dat, batch_size, shuffle=False, num_workers=num_workers)\n",
    "total_step = len(train_loader)\n",
    "\n",
    "it = iter(test_loader)\n",
    "sample_inputs, _ = next(it)\n",
    "\n",
    "in_dim = sample_inputs.shape[-1] * sample_inputs.shape[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Generator (G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=128, image_size=784):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1_1 = nn.Linear(latent_dim, 256)  # accounts for the noise z\n",
    "        self.fc1_1_bn = nn.BatchNorm1d(256)\n",
    "        self.fc1_2 = nn.Linear(10, 256)  # accounts for the labels\n",
    "        self.fc1_2_bn = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc2_bn = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc3_bn = nn.BatchNorm1d(1024)\n",
    "        self.fc4 = nn.Linear(1024, image_size)\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        x = F.relu(self.fc1_1_bn(self.fc1_1(noise)))\n",
    "        y = F.relu(self.fc1_2_bn(self.fc1_2(labels)))\n",
    "        x = torch.cat([x, y], 1)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = F.relu(self.fc3_bn(self.fc3(x)))\n",
    "        x = torch.tanh(self.fc4(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Discriminator (D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_size=784):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1_1 = nn.Linear(image_size, 1024)\n",
    "        self.fc1_2 = nn.Linear(10, 1024)\n",
    "        self.fc2 = nn.Linear(2048, 512)\n",
    "        self.fc2_bn = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc3_bn = nn.BatchNorm1d(256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, images, labels):\n",
    "        x = F.leaky_relu(self.fc1_1(images), 0.2)\n",
    "        y = F.leaky_relu(self.fc1_2(labels), 0.2)\n",
    "        x = torch.cat([x, y], 1)\n",
    "        x = F.leaky_relu(self.fc2_bn(self.fc2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.fc3_bn(self.fc3(x)), 0.2)\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(latent_dim, in_dim)\n",
    "discriminator = Discriminator(in_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss(reduction='mean')\n",
    "def loss_function(out, label):\n",
    "    loss = criterion(out, label)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model and print number of parameters for both G and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)\n",
    "g_params = sum(p.numel() for p in generator.parameters() if p.requires_grad)\n",
    "d_params = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n",
    "print(\"The number of parameters for G is: {}\".format(g_params))\n",
    "print(\"The number of parameters for D is: {}\".format(d_params))\n",
    "print(\"The total number of parameters is: {}\".format(g_params + d_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose and initialize optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(beta_1, beta_2))\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(beta_1, beta_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator.train()\n",
    "discriminator.train()\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "\n",
    "fixed_noise = torch.rand(num_classes, latent_dim).to(device)\n",
    "fixed_labels = np.arange(num_classes)\n",
    "fixed_labels = (torch.from_numpy(fixed_labels)).type(torch.LongTensor)\n",
    "fixed_labels = fixed_labels.to(device)\n",
    "fixed_labels_one_hot = torch.zeros(num_classes, num_classes).to(device)\n",
    "fixed_labels_one_hot.scatter_(1, fixed_labels.view(num_classes, 1), 1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    g_loss_epoch = 0\n",
    "    d_loss_epoch = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        # train Discriminator\n",
    "        images = images.view(batch_size, -1).to(device)\n",
    "\n",
    "        real_labels = torch.ones(batch_size).to(device)\n",
    "        fake_labels = torch.zeros(batch_size).to(device)\n",
    "\n",
    "        labels_one_hot = torch.zeros(batch_size, 10)\n",
    "        labels_one_hot.scatter_(1, labels.view(batch_size, 1).type(torch.LongTensor), 1)\n",
    "        labels_one_hot = labels_one_hot.to(device)\n",
    "\n",
    "        outputs = discriminator(images, labels_one_hot).squeeze()\n",
    "        d_loss_real = loss_function(outputs, real_labels)\n",
    "\n",
    "        z = torch.rand(batch_size, latent_dim).to(device)\n",
    "        z_labels = (torch.rand(batch_size, 1)*num_classes).type(torch.LongTensor)  # ten classes for MNIST\n",
    "        z_labels = z_labels.to(device)\n",
    "        z_labels_one_hot = torch.zeros(batch_size, 10).to(device)\n",
    "        z_labels_one_hot.scatter_(1, z_labels.view(batch_size, 1), 1)\n",
    "\n",
    "        fake_images = generator(z, z_labels_one_hot)\n",
    "        outputs = discriminator(fake_images, z_labels_one_hot).squeeze()\n",
    "        d_loss_fake = loss_function(outputs, fake_labels)\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        d_loss_epoch += d_loss.item()\n",
    "\n",
    "        # train Generator\n",
    "\n",
    "        z = torch.rand(batch_size, latent_dim).to(device)\n",
    "        z_labels = (torch.rand(batch_size, 1)*10).type(torch.LongTensor)  # ten classes for MNIST\n",
    "        z_labels = z_labels.to(device)\n",
    "        z_labels_one_hot = torch.zeros(batch_size, 10).to(device)\n",
    "        z_labels_one_hot.scatter_(1, z_labels.view(batch_size, 1), 1)\n",
    "\n",
    "        fake_images = generator(z, z_labels_one_hot)\n",
    "        outputs = discriminator(fake_images, z_labels_one_hot).squeeze()\n",
    "\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        g_loss_epoch += g_loss.item()\n",
    "        \n",
    "    print('epoch [{}/{}], generator loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, g_loss_epoch / len(train_loader)))\n",
    "    g_losses.append(g_loss_epoch/ len(train_loader))\n",
    "    print('epoch [{}/{}], discriminator loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, d_loss_epoch / len(train_loader)))\n",
    "    d_losses.append(d_loss_epoch/ len(train_loader))\n",
    "    if epoch % sample_interval == 0:\n",
    "        fake_fixed_images = generator(fixed_noise, fixed_labels_one_hot)\n",
    "        fake_fixed_images = denorm(fake_fixed_images)\n",
    "        save_image(fake_fixed_images.cpu(), './cGAN/samples_epoch_{}.png'.format(epoch),nrow = 8)\n",
    "    torch.save(generator.state_dict(), './cGAN/generator.pth')\n",
    "    torch.save(discriminator.state_dict(), './cGAN/discriminator.pth')\n",
    "    \n",
    "np.save('./cGAN/generator_losses.npy', np.array(g_losses))\n",
    "np.save('./cGAN/discriminator_losses.npy', np.array(d_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "generator_losses = np.load('./cGAN/generator_losses.npy')\n",
    "plt.plot(list(range(0,generator_losses.shape[0])), generator_losses)\n",
    "plt.title('Generator Loss')\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "discriminator_losses = np.load('./cGAN/discriminator_losses.npy')\n",
    "plt.plot(list(range(0,discriminator_losses.shape[0])), discriminator_losses)\n",
    "plt.title('Discriminator Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
